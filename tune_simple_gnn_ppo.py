#!/usr/bin/env python3
"""
SimplePPOAgentGNN è¶…å‚æ•°è°ƒä¼˜è„šæœ¬
ä½¿ç”¨Optunaè¿›è¡Œè´å¶æ–¯ä¼˜åŒ–æœç´¢æœ€ä¼˜è¶…å‚æ•°
"""

import optuna
import torch
import numpy as np
import time
import json
import os
from datetime import datetime
from tqdm import tqdm

# å¯¼å…¥å¿…è¦æ¨¡å—
from run_experiments import create_test_graph
from new_environment import GraphPartitionEnvironment
from agent_ppo_gnn_simple import SimplePPOAgentGNN
from metrics import evaluate_partition


# === è¶…å‚æ•°æœç´¢ç©ºé—´å®šä¹‰ ===
def get_search_space(trial: optuna.Trial):
    """
    å®šä¹‰SimplePPOAgentGNNçš„è¶…å‚æ•°æœç´¢ç©ºé—´
    åŸºäºPPOå’ŒGNNçš„ç‰¹æ€§ç²¾å¿ƒè®¾è®¡
    """
    return {
        # === æ ¸å¿ƒå­¦ä¹ è¶…å‚æ•° ===
        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),
        'gamma': trial.suggest_float('gamma', 0.95, 0.999),  # é‡è¦ï¼šå½±å“é•¿æœŸå¥–åŠ±
        'clip_ratio': trial.suggest_float('clip_ratio', 0.1, 0.3),  # PPOæ ¸å¿ƒå‚æ•°
        'entropy_coef': trial.suggest_float('entropy_coef', 0.001, 0.1, log=True),  # æ¢ç´¢vsåˆ©ç”¨
        
        # === ç½‘ç»œæ¶æ„è¶…å‚æ•° ===
        'hidden_dim': trial.suggest_categorical('hidden_dim', [32, 64, 128, 256]),
        'ppo_epochs': trial.suggest_int('ppo_epochs', 2, 8),  # æ›´æ–°è½®æ•°
        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64, 128]),
        
        # === GAEå’Œä»·å€¼å‡½æ•°è¶…å‚æ•° ===
        'gae_lambda': trial.suggest_float('gae_lambda', 0.9, 0.99),
        'value_coef': trial.suggest_float('value_coef', 0.3, 0.7),
        'update_frequency': trial.suggest_int('update_frequency', 4, 16),
        
        # === æ­£åˆ™åŒ–è¶…å‚æ•° ===
        'memory_capacity': trial.suggest_categorical('memory_capacity', [5000, 10000, 20000]),
        
        # === å›ºå®šå‚æ•°ï¼ˆå‡å°‘æœç´¢ç©ºé—´ï¼‰ ===
        'use_tensorboard': False,  # æé«˜è®­ç»ƒé€Ÿåº¦
    }


def objective(trial: optuna.Trial):
    """
    Optunaç›®æ ‡å‡½æ•°ï¼šè®­ç»ƒå¹¶è¯„ä¼°SimplePPOAgentGNN
    """
    run_start_time = time.time()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    print(f"\nğŸ” è¯•éªŒ {trial.number}: å¼€å§‹è¶…å‚æ•°æœç´¢")
    
    # === 1. ç”Ÿæˆè¶…å‚æ•°é…ç½® ===
    config = get_search_space(trial)
    print(f"ğŸ“‹ è¯•éªŒ {trial.number} é…ç½®:")
    for key, value in config.items():
        print(f"   {key}: {value}")
    
    # === 2. åˆ›å»ºæµ‹è¯•ç¯å¢ƒ ===
    # ä½¿ç”¨å›ºå®šçš„å°å›¾è¿›è¡Œå¿«é€ŸéªŒè¯
    NUM_NODES = 12  # é€‚ä¸­å¤§å°ï¼Œæ—¢èƒ½æµ‹è¯•æ€§èƒ½åˆä¸ä¼šå¤ªæ…¢
    NUM_PARTITIONS = 3
    MAX_STEPS_PER_EPISODE = 50  # å‡å°‘æ­¥æ•°åŠ å¿«è®­ç»ƒ
    TRAINING_EPISODES = 350  # å‡å°‘episodeæ•°é‡å¿«é€Ÿè¯„ä¼°
    
    # === ä¼˜åŒ–ï¼šä½¿ç”¨å›ºå®šå›¾ç¡®ä¿å…¬å¹³æ¯”è¾ƒ ===
    graph = create_test_graph(num_nodes=NUM_NODES, seed=42)  # å›ºå®šç§å­ï¼Œæ‰€æœ‰trialä½¿ç”¨ç›¸åŒå›¾
    
    # ä½¿ç”¨é»˜è®¤çš„åŠ¿å‡½æ•°æƒé‡
    default_potential_weights = {'variance': 1.0, 'edge_cut': 1.0, 'modularity': 1.0}
    env = GraphPartitionEnvironment(
        graph,
        NUM_PARTITIONS,
        max_steps=MAX_STEPS_PER_EPISODE,
        gamma=config['gamma'],
        potential_weights=default_potential_weights
    )
    
    # === 3. åˆå§‹åŒ–æ™ºèƒ½ä½“ ===
    # è®¡ç®—çŠ¶æ€å’ŒåŠ¨ä½œç©ºé—´
    node_feature_dim = NUM_PARTITIONS + 2  # åˆ†åŒº + æƒé‡ + åº¦
    action_size = NUM_NODES * NUM_PARTITIONS
    
    agent = None
    best_objective_value = float('inf')
    final_partition = None
    
    try:
        agent = SimplePPOAgentGNN(node_feature_dim, action_size, config)
        
        # === 4. è®­ç»ƒå¾ªç¯ ===
        episode_rewards = []
        episode_variances = []
        best_reward = float('-inf')
        
        # æ·»åŠ æ—©åœæœºåˆ¶
        patience = 50
        no_improvement_count = 0
        best_avg_reward = float('-inf')
        
        pbar = tqdm(range(TRAINING_EPISODES), desc=f"Trial {trial.number}")
        for episode in pbar:
            # é‡ç½®ç¯å¢ƒä¸ºå›¾æ•°æ®æ ¼å¼
            graph_state, _ = env.reset(state_format='graph')
            total_reward = 0
            
            for step in range(MAX_STEPS_PER_EPISODE):
                # æ™ºèƒ½ä½“åŠ¨ä½œé€‰æ‹©
                action = agent.act(graph_state)
                
                # ç¯å¢ƒäº¤äº’
                next_state, reward, done, _, _ = env.step(action)
                
                # è·å–ä¸‹ä¸€ä¸ªçŠ¶æ€çš„å›¾æ•°æ®æ ¼å¼
                next_graph_state = env.get_state('graph')
                
                # å­˜å‚¨ç»éªŒ
                agent.store_transition(reward, done)
                
                # æ›´æ–°çŠ¶æ€
                graph_state = next_graph_state
                total_reward += reward
                
                if done:
                    break
            
            # æ™ºèƒ½ä½“æ›´æ–°
            loss = agent.update()
            
            # è®°å½•æ€§èƒ½
            episode_rewards.append(total_reward)
            
            # è®¡ç®—å½“å‰åˆ†åŒºçš„æ–¹å·®
            if env.partition_assignment is not None:
                from metrics import calculate_weight_variance
                variance = calculate_weight_variance(graph, env.partition_assignment, NUM_PARTITIONS)
                episode_variances.append(variance)
            else:
                episode_variances.append(float('inf'))
            
            # æ›´æ–°æœ€ä½³å¥–åŠ±
            if total_reward > best_reward:
                best_reward = total_reward
                final_partition = env.partition_assignment.copy()
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'reward': f'{total_reward:.2f}',
                'best': f'{best_reward:.2f}',
                'variance': f'{episode_variances[-1]:.3f}',
                'loss': f'{loss:.4f}' if loss > 0 else '0.000'
            })
            
            # === 5. æ—©åœæ£€æŸ¥ ===
            if episode >= 20:  # è‡³å°‘è®­ç»ƒ20ä¸ªepisode
                recent_avg_reward = np.mean(episode_rewards[-10:])  # æœ€è¿‘10ä¸ªepisodeå¹³å‡å¥–åŠ±
                
                if recent_avg_reward > best_avg_reward:
                    best_avg_reward = recent_avg_reward
                    no_improvement_count = 0
                else:
                    no_improvement_count += 1
                
                # æ—©åœæ¡ä»¶
                if no_improvement_count >= patience:
                    print(f"\nâ° è¯•éªŒ {trial.number}: æ—©åœäºç¬¬ {episode} episode (æ— æ”¹å–„ {no_improvement_count} æ¬¡)")
                    break
            
            # === 6. ä¸­é—´å‰ªæ ===
            if episode >= 50 and episode % 25 == 0:
                intermediate_avg_reward = np.mean(episode_rewards[-25:])
                trial.report(intermediate_avg_reward, episode)
                
                if trial.should_prune():
                    print(f"\nâœ‚ï¸ è¯•éªŒ {trial.number}: è¢«å‰ªæäºç¬¬ {episode} episode")
                    raise optuna.exceptions.TrialPruned()
        
        # === 7. æœ€ç»ˆè¯„ä¼° ===
        if final_partition is None:
            final_partition = env.partition_assignment
        
        # å¤„ç†æ— æ•ˆåˆ†åŒº
        if final_partition is None or len(np.unique(final_partition)) < NUM_PARTITIONS:
            print(f"âŒ è¯•éªŒ {trial.number}: ç”Ÿæˆäº†æ— æ•ˆåˆ†åŒº")
            return float('inf')
        
        # è¯„ä¼°æœ€ç»ˆåˆ†åŒºè´¨é‡
        eval_results = evaluate_partition(graph, final_partition, NUM_PARTITIONS, print_results=False)
        
        # === 8. ç›®æ ‡å‡½æ•°è®¾è®¡ ===
        # ç»¼åˆè€ƒè™‘å¤šä¸ªæŒ‡æ ‡ï¼Œæƒé‡å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
        normalized_cut = eval_results["normalized_cut"]
        weight_imbalance = eval_results["weight_imbalance"]
        weight_variance = eval_results["weight_variance"]
        
        # å¤åˆç›®æ ‡å‡½æ•°ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        objective_value = (
            0.5 * normalized_cut +           # ä¸»è¦ç›®æ ‡ï¼šæœ€å°åŒ–åˆ‡è¾¹
            0.3 * (weight_imbalance - 1) +   # å¹³è¡¡æ€§æƒ©ç½š
            0.2 * (weight_variance / (NUM_NODES * 5))  # æ–¹å·®æƒ©ç½šï¼ˆå½’ä¸€åŒ–ï¼‰
        )
        
        # å¥–åŠ±ç¨³å®šæ€§ï¼ˆè´Ÿæ–¹å·®å¥–åŠ±ï¼‰
        if len(episode_rewards) > 10:
            reward_stability = 1.0 / (1.0 + np.std(episode_rewards[-20:]))
            objective_value -= 0.1 * reward_stability  # å¥–åŠ±ç¨³å®šçš„è¯•éªŒ
        
        print(f"\nğŸ“Š è¯•éªŒ {trial.number} ç»“æœ:")
        print(f"   å½’ä¸€åŒ–åˆ‡è¾¹: {normalized_cut:.4f}")
        print(f"   æƒé‡ä¸å¹³è¡¡: {weight_imbalance:.4f}")
        print(f"   æƒé‡æ–¹å·®: {weight_variance:.4f}")
        print(f"   ç»¼åˆç›®æ ‡å€¼: {objective_value:.6f}")
        print(f"   è®­ç»ƒæ—¶é•¿: {time.time() - run_start_time:.2f}ç§’")
        
        return objective_value
        
    except Exception as e:
        print(f"ğŸ’¥ è¯•éªŒ {trial.number} å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return float('inf')
        
    finally:
        # === 9. æ¸…ç†èµ„æº ===
        if agent is not None:
            del agent
        del env
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        print(f"ğŸ§¹ è¯•éªŒ {trial.number}: èµ„æºæ¸…ç†å®Œæˆ")


def run_hyperparameter_optimization(n_trials=100, n_jobs=1):
    """
    è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–
    """
    print("ğŸš€ å¼€å§‹SimplePPOAgentGNNè¶…å‚æ•°ä¼˜åŒ–")
    print(f"ğŸ“Š è®¡åˆ’è¯•éªŒæ¬¡æ•°: {n_trials}")
    print(f"âš¡ å¹¶è¡Œä»»åŠ¡æ•°: {n_jobs}")
    
    # === åˆ›å»ºOptunaç ”ç©¶ï¼ˆæ”¯æŒæŒä¹…åŒ–å­˜å‚¨ï¼‰ ===
    study_name = "simple_ppo_gnn_optimization"  # å›ºå®šåç§°ï¼Œæ”¯æŒè·¨sessionç´¯ç§¯
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # SQLiteæ•°æ®åº“å­˜å‚¨ï¼Œæ”¯æŒå¤šæ¬¡è¿è¡Œç´¯ç§¯ç»“æœ
    storage_name = "sqlite:///optuna_simple_ppo_gnn_study.db"
    
    # ä½¿ç”¨TPEé‡‡æ ·å™¨å’ŒMedianPrunerå‰ªæå™¨
    study = optuna.create_study(
        study_name=study_name,
        storage=storage_name,       # æŒä¹…åŒ–å­˜å‚¨
        load_if_exists=True,        # å¦‚æœå·²å­˜åœ¨åˆ™åŠ è½½ä¹‹å‰çš„ç»“æœ
        direction='minimize',       # æœ€å°åŒ–ç›®æ ‡å‡½æ•°
        sampler=optuna.samplers.TPESampler(seed=42),  # TPEé‡‡æ ·å™¨
        pruner=optuna.pruners.MedianPruner(
            n_startup_trials=10,    # å‰10ä¸ªè¯•éªŒä¸å‰ªæ
            n_warmup_steps=25,      # 25ä¸ªepisodeåå¼€å§‹å‰ªæ
            interval_steps=25       # æ¯25ä¸ªepisodeæ£€æŸ¥ä¸€æ¬¡
        )
    )
    
    print(f"ğŸ”¬ åˆ›å»ºç ”ç©¶: {study_name}")
    print(f"ğŸ’¾ æ•°æ®åº“å­˜å‚¨: {storage_name}")
    
    # === æ˜¾ç¤ºä¹‹å‰è¿è¡Œçš„ç»“æœ ===
    if len(study.trials) > 0:
        print(f"ğŸ“š å·²æœ‰è¯•éªŒæ•°: {len(study.trials)}")
        print(f"ğŸ† å½“å‰æœ€ä½³ç›®æ ‡å€¼: {study.best_value:.6f}")
        print(f"ğŸ”§ å½“å‰æœ€ä½³å‚æ•°é¢„è§ˆ:")
        for key, value in list(study.best_params.items())[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå‚æ•°
            print(f"   {key}: {value}")
        print(f"   ... (å…±{len(study.best_params)}ä¸ªå‚æ•°)")
    else:
        print("ğŸ†• è¿™æ˜¯å…¨æ–°çš„ç ”ç©¶ï¼Œæ²¡æœ‰å†å²æ•°æ®")
    
    # === è¿è¡Œä¼˜åŒ– ===
    start_time = time.time()
    try:
        study.optimize(objective, n_trials=n_trials, n_jobs=n_jobs)
    except KeyboardInterrupt:
        print("â¸ï¸ ç”¨æˆ·ä¸­æ–­ä¼˜åŒ–è¿‡ç¨‹")
    
    total_time = time.time() - start_time
    
    # === ç»“æœåˆ†æ ===
    print(f"\nğŸ‰ ä¼˜åŒ–å®Œæˆï¼æ€»ç”¨æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    print(f"âœ… å®Œæˆè¯•éªŒæ•°: {len(study.trials)}")
    print(f"ğŸ† æœ€ä½³è¯•éªŒ: {study.best_trial.number}")
    print(f"ğŸ¯ æœ€ä½³ç›®æ ‡å€¼: {study.best_value:.6f}")
    
    print(f"\nğŸ”§ æœ€ä½³è¶…å‚æ•°:")
    for key, value in study.best_params.items():
        print(f"   {key}: {value}")
    
    # === ä¿å­˜ç»“æœ ===
    results_dir = f"optimization_results/{timestamp}"
    os.makedirs(results_dir, exist_ok=True)
    
    # ä¿å­˜æœ€ä½³å‚æ•°
    best_params_file = f"{results_dir}/best_simple_ppo_gnn_params.json"
    with open(best_params_file, 'w') as f:
        json.dump(study.best_params, f, indent=2)
    print(f"ğŸ’¾ æœ€ä½³å‚æ•°å·²ä¿å­˜åˆ°: {best_params_file}")
    
    # ä¿å­˜è¯¦ç»†ç ”ç©¶ç»“æœ
    study_file = f"{results_dir}/study_simple_ppo_gnn.pkl"
    try:
        import pickle
        with open(study_file, 'wb') as f:
            pickle.dump(study, f)
        print(f"ğŸ’¾ ç ”ç©¶æ•°æ®å·²ä¿å­˜åˆ°: {study_file}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜ç ”ç©¶æ•°æ®å¤±è´¥: {e}")
        # ä¿å­˜ä¸ºJSONæ ¼å¼ä½œä¸ºå¤‡é€‰
        study_json_file = f"{results_dir}/study_trials.json"
        trials_data = []
        for trial in study.trials:
            trial_data = {
                'number': trial.number,
                'value': trial.value,
                'params': trial.params,
                'state': str(trial.state)
            }
            trials_data.append(trial_data)
        
        with open(study_json_file, 'w') as f:
            json.dump(trials_data, f, indent=2)
        print(f"ğŸ’¾ è¯•éªŒæ•°æ®å·²ä¿å­˜åˆ°: {study_json_file}")
    
    # === å¯è§†åŒ–åˆ†æï¼ˆä¿®å¤ä¸­æ–‡ä¹±ç ï¼‰ ===
    try:
        import matplotlib.pyplot as plt
        
        # è®¾ç½®è‹±æ–‡å­—ä½“ï¼Œé¿å…ä¸­æ–‡ä¹±ç 
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
        
        # å‚æ•°é‡è¦æ€§å›¾
        fig = optuna.visualization.matplotlib.plot_param_importances(study)
        plt.title("SimplePPOAgentGNN Hyperparameter Importance", fontsize=12, pad=20)
        plt.xlabel("Importance", fontsize=10)
        plt.ylabel("Hyperparameter", fontsize=10)
        plt.tight_layout(pad=2.0)  # å¢åŠ è¾¹è·é¿å…é‡å 
        plt.savefig(f"{results_dir}/param_importance.png", dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š Parameter importance plot saved")
        
        # ä¼˜åŒ–å†å²å›¾
        fig = optuna.visualization.matplotlib.plot_optimization_history(study)
        plt.title("SimplePPOAgentGNN Optimization History", fontsize=12, pad=20)
        plt.xlabel("Trial Number", fontsize=10)
        plt.ylabel("Objective Value", fontsize=10)
        plt.tight_layout(pad=2.0)
        plt.savefig(f"{results_dir}/optimization_history.png", dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“ˆ Optimization history plot saved")
        
        # å‚æ•°å…³ç³»å›¾ï¼ˆå¦‚æœtrialæ•°>=10ï¼‰
        if len(study.trials) >= 10:
            try:
                fig = optuna.visualization.matplotlib.plot_parallel_coordinate(study)
                plt.title("Hyperparameter Parallel Coordinates", fontsize=12, pad=20)
                plt.tight_layout(pad=2.0)
                plt.savefig(f"{results_dir}/parallel_coordinates.png", dpi=300, bbox_inches='tight')
                plt.close()
                print(f"ğŸ“Š Parallel coordinates plot saved")
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡å¹³è¡Œåæ ‡å›¾: {e}")
        
        plt.close('all')  # ç¡®ä¿å…³é—­æ‰€æœ‰å›¾å½¢
        
    except ImportError:
        print("âš ï¸ matplotlib not installed, skipping visualization")
    except Exception as e:
        print(f"âš ï¸ Visualization error: {e}")
    
    return study


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="SimplePPOAgentGNNè¶…å‚æ•°ä¼˜åŒ–")
    parser.add_argument("--n-trials", type=int, default=50,
                       help="è¯•éªŒæ¬¡æ•° (é»˜è®¤: 50)")
    parser.add_argument("--n-jobs", type=int, default=2,
                       help="å¹¶è¡Œä»»åŠ¡æ•° (é»˜è®¤: 2, æ¨è1-3)")
    parser.add_argument("--quick-test", action="store_true",
                       help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼ (10ä¸ªè¯•éªŒ)")
    
    args = parser.parse_args()
    
    if args.quick_test:
        print("ğŸ§ª å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
        n_trials = 10
        n_jobs = 1
    else:
        n_trials = args.n_trials
        n_jobs = args.n_jobs
    
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    print("ğŸ”§ ç¯å¢ƒæ£€æŸ¥:")
    print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
    
    # è¿è¡Œä¼˜åŒ–
    study = run_hyperparameter_optimization(n_trials=n_trials, n_jobs=n_jobs)
    
    print("\nğŸŠ ä¼˜åŒ–ä»»åŠ¡å®Œæˆï¼")
    return study


if __name__ == "__main__":
    main() 