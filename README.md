1. environment.py: 你的 GraphPartitionEnvironment 类。如果算法 B 需要状态是 PyG 的 Data 对象，可能需要修改这个文件。
2. agent_dqn_basic.py: 实现算法 A 的 DQN 智能体。
3. agent_gnn.py: 实现算法 B 的 GNN-based 智能体 (例如 PPO+GNN)。
4. metrics.py: 编写计算你选择的评估指标的函数 (方差、切割边、模块度等)。这些函数应该接收图对象 graph 和分区分配数组 partition_assignment 作为输入。
5. baselines.py: 编写运行随机划分和 METIS/KaHIP 的函数。
6. run_experiments.py: 主要的脚本，负责加载图、运行各种算法、收集结果。
7. configs/ (可选): 存放配置文件 (数据集路径、算法超参数等)。
8. results/: 存放实验结果数据 (CSV 文件)。
9. plots/: 存放生成的图表 (PNG 文件)。



### SOME EXPERIENCE
1. 超参数问题：
    - episode: 训练的总回合数
        - 增加：提高解决方案质量，但延长训练时间
        - 减少：加快训练，但可能导致结果不佳
    - max_steps: 每个回合的最大步数
        - 增加：允许更多探索，但可能导致过拟合
        - 减少：加快训练，但可能导致结果不佳
    - batch_size: 每次训练的样本数量
        - 增加：提高训练稳定性，但增加内存消耗
        - 减少：加快训练，但可能导致结果不佳
    - gamma: 折扣因子
        - 增加：更关注长期奖励，但可能导致短期奖励被忽视
        - 减少：更关注短期奖励，但可能导致长期奖励被忽视
    - learning_rate: 学习率
        - 增加：加快收敛速度，但可能导致不稳定
        - 减少：提高稳定性，但收敛速度变慢
    - epsilon: 探索率
        - 增加：更多探索，但可能导致不稳定
        - 减少：更关注利用，但可能导致局部最优
    - target_update_interval: 目标网络更新频率
        - 增加：提高稳定性，但收敛速度变慢
        - 减少：加快收敛速度，但可能导致不稳定
2. batch_size与gpu利用率的关系：
在gnn模型中，调大batch_size会导致gpu利用率下降的问题很常见，问题分析：  
图批处理较为特殊，首先不规则的图结构会导致内存访问模式不连续，增大batch可能会加剧问题；
其次，每次_state_to_pyg_data调用都会创建新的numpy数组，执行循环操作，cpu->gpu传输数据，batch变大会增加串行操作的占比
3. 在gnn训练过程中发现传统架构下的dqn有210.85it/s但是在gnn模型下只有50it/s的速度，原因如下：  
    - 计算复杂度高了很多：
        - GNN 需要进行图卷积操作，涉及邻居节点信息的聚合
        - 每一层 GCNConv 的计算复杂度与边数成正比
        - 传统 DQN 只进行简单的矩阵乘法
    - 数据结构的差异：
        - GNN 使用的 PyTorch Geometric 数据结构更复杂
        - 为每个样本构建 PyG Data 对象开销很大
    - 内存分配和数据传输:
        - 图批处理（Batch）操作比简单向量批处理复杂得多
        - 在 GPU 和 CPU 之间传输图结构数据更耗时
    - 批处理机制：
        - GNN 的批处理需要处理不同大小的图和节点索引
        - Batch.from_data_list() 操作需要处理每个图的边索引的偏移量
   






算法的实现与优化都感觉一个非常非常庞大的任务，很多时候都是在摸黑操作，像计算机一样的精密结构牵一发而动全身