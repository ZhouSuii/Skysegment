import optuna
import os
import json
import networkx as nx
import numpy as np

# å¯¼å…¥æ‚¨é¡¹ç›®ä¸­çš„æ ¸å¿ƒå‡½æ•°
from run_experiments import train_gnn_ppo_agent, load_graph_from_file
from metrics import evaluate_partition

def objective(trial):
    """
    è¿™æ˜¯Optunaçš„ç›®æ ‡å‡½æ•°ï¼ŒOptunaä¼šä¸æ–­è°ƒç”¨å®ƒæ¥å¯»æ‰¾æœ€ä¼˜è§£ã€‚
    æ¯ä¸€æ¬¡è°ƒç”¨ï¼ŒOptunaéƒ½ä¼šä»æˆ‘ä»¬å®šä¹‰çš„æœç´¢ç©ºé—´ä¸­å–ä¸€ç»„æ–°çš„è¶…å‚æ•°ã€‚
    """
    print(f"\n===== Trial #{trial.number} starting... =====")

    # 1. å®šä¹‰è¶…å‚æ•°çš„æœç´¢ç©ºé—´
    #    æˆ‘ä»¬å‘Šè¯‰Optunaå¯ä»¥åœ¨ä»€ä¹ˆèŒƒå›´å†…è°ƒæ•´å‚æ•°
    config = {
        "episodes": 500,  # æ¯æ¬¡è¯•éªŒçš„è®­ç»ƒè½®æ•°å¯ä»¥å°‘ä¸€ç‚¹ï¼Œä»¥åŠ å¿«é€Ÿåº¦
        "max_steps": 100,
        "gnn_ppo_config": {
            # === å¥–åŠ±å‡½æ•°æƒé‡ ===
            "potential_weights": {
                "variance": trial.suggest_float("variance_weight", 0.1, 20.0, log=True),
                "edge_cut": trial.suggest_float("edge_cut_weight", 0.1, 10.0, log=True),
                "modularity": trial.suggest_float("modularity_weight", 0.1, 10.0, log=True),
            },
            # === GNN-PPO Agentè‡ªèº«å‚æ•° ===
            "entropy_coef": trial.suggest_float("entropy_coef", 1e-3, 0.1, log=True),
            "clip_ratio": trial.suggest_float("clip_ratio", 0.1, 0.3),
            "hidden_dim": 2048, # ä¿æŒä¸å˜
            "num_partitions": 3 # ä¿æŒä¸å˜, æˆ–æ ¹æ®å›¾è°ƒæ•´
        }
    }

    # 2. è¿è¡Œä¸€æ¬¡è®­ç»ƒ
    #    æˆ‘ä»¬å¤ç”¨æ‚¨å·²æœ‰çš„è®­ç»ƒå‡½æ•°
    try:
        partition, _, _, _, _, _ = train_gnn_ppo_agent(
            graph,
            num_partitions,
            config,
            results_dir=f"results/tuning_trials/trial_{trial.number}"
        )
    except Exception as e:
        print(f"Trial #{trial.number} failed with an exception: {e}")
        # å¦‚æœè®­ç»ƒä¸­é€”å‡ºé”™ï¼Œå‘Šè¯‰Optunaè¿™æ¬¡è¯•éªŒå¤±è´¥äº†
        raise optuna.exceptions.TrialPruned()


    # 3. è¯„ä¼°ç»“æœå¹¶è®¡ç®—ä¸€ä¸ªæœ€ç»ˆ"åˆ†æ•°"
    #    è¿™ä¸ªåˆ†æ•°æ˜¯ç”¨æ¥å‘Šè¯‰Optunaè¿™æ¬¡è°ƒå‚çš„æ•ˆæœæœ‰å¤šå¥½
    if partition is None:
        print(f"Trial #{trial.number} did not produce a valid partition.")
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„åˆ’åˆ†ï¼Œä¹Ÿè§†ä¸ºå¤±è´¥
        raise optuna.exceptions.TrialPruned()

    eval_results = evaluate_partition(graph, partition, num_partitions, print_results=False)

    # === å®šä¹‰æˆ‘ä»¬çš„ä¼˜åŒ–ç›®æ ‡ ===
    # æˆ‘ä»¬å¸Œæœ› æ–¹å·®(variance) å’Œ å½’ä¸€åŒ–åˆ‡è¾¹(normalized_cut) è¶Šå°è¶Šå¥½ã€‚
    # æˆ‘ä»¬ç»™å®ƒä»¬åˆ†é…ä¸€ä¸ªå›ºå®šçš„é‡è¦æ€§æƒé‡ï¼Œè¿™é‡Œæˆ‘ä»¬è®¤ä¸ºå®ƒä»¬åŒç­‰é‡è¦ã€‚
    # æ³¨æ„ï¼šè¿™ä¸ªæƒé‡å’Œå¥–åŠ±å‡½æ•°é‡Œçš„æƒé‡æ˜¯ä¸¤ä¸ªæ¦‚å¿µã€‚
    score = (1.0 * eval_results["weight_variance"]) + (10000 * eval_results["normalized_cut"])
    
    # å¢åŠ ä¸€ä¸ªæƒ©ç½šé¡¹ï¼Œå¦‚æœåˆ†åŒºä¸å¹³è¡¡ï¼Œåˆ†æ•°ä¼šå˜å¾—å¾ˆå·®
    if eval_results["weight_imbalance"] > 2.0:
        score += 1e9 # å·¨å¤§çš„æƒ©ç½š

    print(f"TRIAL #{trial.number} finished.")
    print(f"  - Params: {trial.params}")
    print(f"  - Results: variance={eval_results['weight_variance']:.2f}, norm_cut={eval_results['normalized_cut']:.4f}")
    print(f"  - FINAL SCORE: {score:.2f} (the lower the better)")

    return score


if __name__ == "__main__":
    # åŠ è½½å›¾
    real_graph_path = "ctu_airspace_graph_1900_2000_kmeans.graphml"
    print(f"ğŸ”„ Loading graph for tuning: {real_graph_path}")
    graph = load_graph_from_file(real_graph_path)
    # é‡æ–°ç¼–å·
    node_mapping = {old_node: i for i, old_node in enumerate(graph.nodes())}
    graph = nx.relabel_nodes(graph, node_mapping)
    num_partitions = 3 if graph.number_of_nodes() > 15 else 2

    # åˆ›å»ºä¸€ä¸ªOptuna "study" å¯¹è±¡ï¼Œå®ƒä¼šç®¡ç†æ•´ä¸ªä¼˜åŒ–è¿‡ç¨‹
    # æˆ‘ä»¬è®¾ç½®ä¸€ä¸ªåå­—ï¼Œæ–¹ä¾¿æœªæ¥ç»§ç»­è¿è¡Œ
    study_name = "gnn_ppo_tuning_study"
    storage_name = f"sqlite:///{study_name}.db"
    
    print(f"ğŸš€ Starting Optuna study: {study_name}")
    print(f"Results will be stored in: {storage_name}")
    
    study = optuna.create_study(
        study_name=study_name,
        storage=storage_name,
        direction="minimize", # æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©scoreæœ€å°åŒ–
        load_if_exists=True # å¦‚æœæ•°æ®åº“æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°±ä»ä¸Šæ¬¡ç»“æŸçš„åœ°æ–¹ç»§ç»­
    )

    # å¯åŠ¨ä¼˜åŒ–ï¼Optunaä¼šè°ƒç”¨objectiveå‡½æ•°50æ¬¡
    study.optimize(objective, n_trials=50)

    # å®éªŒç»“æŸï¼Œæ‰“å°æœ€ä½³ç»“æœ
    print("\n\nğŸ‰ğŸ‰ğŸ‰ TUNING COMPLETE! ğŸ‰ğŸ‰ğŸ‰")
    print(f"Best trial: #{study.best_trial.number}")
    print(f"  - Score: {study.best_trial.value:.2f}")
    print("  - Best hyperparameters:")
    for key, value in study.best_trial.params.items():
        print(f"    - {key}: {value}")

    # å°†æœ€ä½³å‚æ•°ä¿å­˜åˆ°JSONæ–‡ä»¶
    best_params_config = {
        "gnn_ppo_config": {
            "potential_weights": {
                "variance": study.best_trial.params["variance_weight"],
                "edge_cut": study.best_trial.params["edge_cut_weight"],
                "modularity": study.best_trial.params["modularity_weight"],
            },
            "learning_rate": study.best_trial.params["learning_rate"],
            "entropy_coef": study.best_trial.params["entropy_coef"],
            "clip_ratio": study.best_trial.params["clip_ratio"],
        }
    }
    
    output_path = "configs/best_params_generated.json"
    with open(output_path, "w") as f:
        json.dump(best_params_config, f, indent=4)
        
    print(f"\nâœ… Best parameters saved to {output_path}")
    print("You can now use this file to configure your final experiment run.") 